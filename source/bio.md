---
layout: page
title: Bio
permalink: /bio/
---

Since 2019 I am a Research Engineer at DeepMind, working on a range of language and bioinformatics problems. 

I graduated from Moscow State University in 2014 with a major in Computer Science.
During the last years of studies I focused on Machine Learning and joined [Yandex School Of Data Analysis](https://yandexdataschool.com/), where I studied such courses as Probabilistic Graphical Models by [Dmitry Vetrov](https://cs.hse.ru/en/bayesgroup/people/vetrov), Statistical Machine Translation by [David Talbot](https://research.google.com/pubs/DavidTalbot.html), Deep Learning for Computer Vision by [Victor Lempitsky](http://sites.skoltech.ru/compvision/members/vilem/).

Then I did my PhD in Natural Language Understanding under supervision of Prof. [Konstantin Vorontsov](https://scholar.google.com/citations?user=KIW4fnsAAAAJ&hl=en&authuser=1). We developed [Additive Regularization of Topic Models](bigartm.org) to learn probabilistic interpretable sparse embeddings for words, documents and other modalities.

As a PhD student, I did several internships:

* Winter 2017-2018 - ETH Zurich, Data Analytics Lab (Thomas Hofmann's group). Research on interpretability and sparsity of word embeddings. 

* Summer 2017 - Google, Assistant team. Research on soft and hard attention in neural networks for dialogue systems.

* Fall-Winter 2016 - [Yandex Data Factory](https://yandexdatafactory.com/). Several projects in applied machine learning: time series prediction for ATM withdrawal, news retrieval, news clustering and de-duplicating.

* Summer 2016 - Google, Ads Quality team. Models to expand Ads categories with new concepts based on distributional similarities.

You can download my CV from 2017 [here]({{ site.url }}/images/CV_2017.pdf).